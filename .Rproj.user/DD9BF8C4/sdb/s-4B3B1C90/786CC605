{
    "collab_server" : "",
    "contents" : "rm(list=ls())\ngc()\nlibrary(data.table)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(ggpubr)\nlibrary(zoo)\n\nUS_seir_forecasts <- readRDS('data/US_seir_forecasts_unif_2_7.Rd')\nsetkey(US_seir_forecasts,replicate,date)\n## We need to rollapply a sum for every week to capture weekly ILI\nUS_seir_forecasts[,weekly_I:=rollapply(I,sum,fill=NA,align='left',w=7),by=replicate]\nsaveRDS(US_seir_forecasts,'data/US_seir_forecasts_unif_weekly.Rd')\n\nILI <- read.csv('data/number_excess_ili_cases.csv',stringsAsFactors = F) %>% as.data.table\nILI[,week:=as.Date(week)]\n\nUS_seir_forecasts[date %in% setdiff(unique(ILI$week),NA)][!is.na(weekly_I),c('replicate','date','weekly_I')] %>%\n  write.csv('data/weekly_I_across_replicates.csv')\n\nUS_seir_forecasts[,date:=shift(date,4,type='lead'),by=replicate]\nUS_seir_forecasts[date %in% setdiff(unique(ILI$week),NA)][!is.na(weekly_I),c('replicate','date','weekly_I')] %>%\n  write.csv('data/weekly_I_across_replicates_4d_lag.csv')\n\nrm(list=ls())\ngc()\n\n# distribution over replicates --------------------------------------------\n\n\n\n# Calculating Clinical Rates -----------------------------------------------------\nclinical_rate_calculator <- function(week='2020-03-15',method='gam',\n                                     start_date='2020-01-15',time_onset_to_doc=0){\n  ILI <- read.csv('data/US_total_weekly_excess_ili_no_mizumoto.csv',stringsAsFactors = F) %>% as.data.table\n  ILI[,week:=as.Date(date)]\n  \n  if (week=='latest'){\n    wk<- max(ILI$week,na.rm=T)\n  } else {\n    wk <- as.Date(week)\n  }\n  \n  if (class(start_date)!='Date'){\n    start_date <- as.Date(start_date)\n  }\n  # \n  # if (statistic=='mean'){\n  #   Excess_ILI <- ILI[week==wk,(Excess_ILI=sum(avg,na.rm=T))]\n  # } else { #median\n  #   Excess_ILI <- ILI[week==wk,(Excess_ILI=sum(p50,na.rm=T))]\n  # }\n  Excess_ILI <- mean(ILI[week==wk]$mean)\n  \n  US_seir_forecasts <- readRDS('data/US_seir_forecasts_unif_weekly.Rd')\n  setkey(US_seir_forecasts,replicate,date)\n  date_shift = as.numeric(min(US_seir_forecasts$date)-start_date)\n  US_seir_forecasts[,date:=shift(date,type='lead',n=date_shift),by=replicate]\n  \n  X = US_seir_forecasts[date==wk-time_onset_to_doc,\n                        list(clinical_rate=Excess_ILI/weekly_I),by=GrowthRate]\n  \n  if (method=='loess'){\n    fit <- loess(log(clinical_rate)~log(GrowthRate),data=X)\n    X[,predicted_clinical_rate:=exp(fit$fitted)]\n  } else {\n    fit <- mgcv::gam(log(clinical_rate)~s(log(GrowthRate)),data=X)\n    X[,predicted_clinical_rate:=exp(fit$fitted.values)]\n  }\n  X[,possible:=clinical_rate<1]\n  X[,DoublingTime:=log(2)/GrowthRate]\n  setkey(X,GrowthRate)\n  return(list('Data'=X,'fit'=fit))\n}\n\nCR <- clinical_rate_calculator(time_onset_to_doc=4)\nggplot(CR$Data,aes(DoublingTime,clinical_rate,alpha=factor(possible)))+\n  geom_point()+\n  scale_alpha_manual(values=c(0.03,0.15))+\n  scale_y_continuous(trans='log',breaks=10^(-5:5))+\n  scale_x_continuous(trans='log',breaks=1:7)+\n  geom_line(aes(DoublingTime,predicted_clinical_rate),lwd=2,alpha=1,col=rgb(0,.2,0.8))+\n  theme(legend.position = 'none')+\n  ggtitle('Estimated clinical rate, 4 day lag')\nggsave('figures/Clinical_rate_v_Doubling_time_4d_lag.png',height=8,width=8,units='in')\n\nlag_times <- c(0,4,8)\nfor (lag in lag_times){\n  dum <- clinical_rate_calculator(time_onset_to_doc=lag)\n  if (lag==0){\n    CR <- dum$Data\n    CR[,delay_to_doc:=lag]\n  } else {\n    dum$Data[,delay_to_doc:=lag]\n    CR <- rbind(CR,dum$Data)\n  }\n}\n\nlabel_figs <- function(strings)  paste(strings,'days')\n\n\n\n\ng1=ggplot(CR[DoublingTime<4],aes(DoublingTime,clinical_rate,alpha=factor(possible),by=delay_to_doc))+\n  geom_point()+\n  scale_alpha_manual(values=c(0.01,0.15))+\n  scale_y_continuous(trans='log',breaks=10^(-5:3),limits=c(6e-3,1e3))+\n  scale_x_continuous(trans='log',breaks=1:7)+\n  geom_line(aes(DoublingTime,predicted_clinical_rate),lwd=2,alpha=1,col=rgb(0,.2,0.8))+\n  theme_bw(base_size=25)+\n  theme(legend.position = 'none')+\n  geom_vline(xintercept = 3.5,lty=1,lwd=2,col='black',alpha=1)+\n  geom_vline(xintercept = 1.91,lty=2,lwd=2,col='black',alpha=1)+\n  facet_wrap(.~delay_to_doc,labeller=labeller(delay_to_doc=label_figs),ncol=length(lag_times))\ng1\n# ggsave('figures/Clinical_rate_v_Doubling_time_by_delay.png',height=8,width=14,units='in')\nggsave('figures/Clinical_rate_v_Doubling_time_by_delay_transparent.png',height=8,width=14,units='in',bg='transparent')\n\n\n\n# Comparing ILI to US forecasts -------------------------------------------\n\n##### load ILI data\n## these data have a mizumoto 17.9% asymptomatic correction\nILI <- read.csv('data/number_excess_ili_cases.csv',stringsAsFactors = F) %>% as.data.table\nILI[,week:=as.Date(week)] \n\n##### Merge probabilities with US SEIR forecasts\nweights <- read.csv('data/distribution_over_replicates.csv') %>% as.data.table\nUS <- readRDS('data/US_seir_forecasts_unif_weekly.Rd')\nsetkey(weights,replicate)\nsetkey(US,replicate)\nUS <- US[weights]\n#### compute doubling time\nUS[,DoublingTime:=log(2)/GrowthRate]\n\n##### posterior samples w/ mizumoto correction - will use to visualize mean ILI vs. Forecasts\nili <- read.csv('data/posterior_samples_us_weekly_I.csv') %>% as.data.table\nili[,date:=as.Date(date)-4]\nili <- ili[,list(weekly_I=mean(weekly_I),\n          replicate=unique(as.numeric(date))+14000,\n          DoublingTime=2.9,\n          probability=max(US$probability)),by=date]\n\n\n\n##### function to convert probabilities to weights for transparency setting alpha=weight\nconvertP<-function(x){\n  x[x==0]<-min(x[x>0])/10\n  y <- log(x)\n  y <- (y-min(y))/(max(y)-min(y))\n  return(y)\n}\nUS[,weight:=convertP(probability)]\nili[,weight:=convertP(probability)]\n\n\n########## subsampling replicates for plotting\n### use this if many probabilities are = 0\nn_reps_for_plotting <- 3e3\nn_nonzero <- length(unique(US[probability>0,replicate]))\nreplicates <- c(unique(US[probability>0,replicate]),\n                sample(unique(US[probability==0]$replicate),\n                       n_reps_for_plotting-n_nonzero))\n\nr_set <- unique(US$GrowthRate)\nr_slow <- log(2)/3.5\nr_fast <- log(2)/1.91\n\nrep_slow <- unique(US$replicate)[order(abs(r_slow-r_set))]\nrep_fast <- unique(US$replicate)[order(abs(r_fast-r_set))]\n## finding a fast replicate: which curve, with unknown scaling factor, \n## comes closest to interpolating observed ILI?\n\n\n### use this if most probabilities > 0\n# probs <- US[,list(prob=unique(probability)),by=replicate]\n# replicates <- sample(probs$replicate,1e3,prob = probs$prob,replace=F)\n\n########### plotting forecasts vs. ILI\ng2=ggplot(US[replicate %in% replicates & date<=as.Date('2020-03-15')],\n          aes(date,weekly_I,color=DoublingTime,by=factor(replicate),alpha=weight))+\n  geom_line()+\n  ggtitle('COVID Forecasts vs. ILI')+\n  scale_y_continuous(trans='log',breaks=10^(1:9),name='Past Week Infectious-Days')+\n  # geom_hline(yintercept = ili$weekly_I,lty=3,col='red',lwd=2)+\n  theme_bw(base_size = 25)+\n  theme(legend.position = 'none')+\n  geom_point(data=ili,col='red',pch=16,cex=8)+\n  geom_line(data=US[replicate==rep_slow[1] & date<=as.Date('2020-03-15')],lty=1,lwd=2,col='black',alpha=1)+\n  geom_line(data=US[replicate==rep_fast[1] & date<=as.Date('2020-03-15')],lty=2,lwd=2,col='black',alpha=1)+\n  scale_alpha_continuous(range=c(0.01,1))\ng2\nggsave('figures/Epidemic_curve_estimation.png',height=8,width=8,unit='in',bg='transparent')\n\n\n\n# Forecast plotting -------------------------------------------------------\n\ng3=ggplot(US[replicate %in% replicates & date>as.Date('2020-02-28')],\n          aes(date,I,by=factor(replicate),alpha=weight))+\n  geom_line()+\n  ggtitle('US SEIR forecasts')+\n  theme(legend.position = c(0.9,0.85))+\n  scale_alpha_continuous(range=c(0.01,0.5))+\n  scale_y_continuous('Number Infected')+\n  theme_bw(base_size=25)+\n  theme(legend.position='none')\ng3\nggsave('figures/SEIR_forecasts.png',height=10,width=14,units='in')\n\n\n\n# Plot forecasts + clinical rate estimation -------------------------------\nggarrange(g3,g1,nrow=2)\nggsave('figures/Clinical_rate_estimation.png',height=12,width=10,units='in')\n\n\n\n# Clinical Rate of avg growth rate ----------------------------------------\n\nr_deaths <- 2.955883\nCR <- clinical_rate_calculator(time_onset_to_doc = 4)  ## assume 4-day lag from onset of infectiousness to doc visit\nCR$fit %>% predict(newdata=data.frame('GrowthRate'=r_deaths)) %>% exp   ## clinical rate for state growths\n\n\n\n# CFR estimation ----------------------------------------------------------\n\nD <- read.csv('data/covid-19-data/time_series_covid19_deaths_US_JH.csv',stringsAsFactors = F) %>% as.data.table\nD <- D[Country_Region=='US']\nobs <- grepl('20',colnames(D))\ndts <- colnames(D)[obs] %>% gsub('X','',.) %>% as.Date(.,format='%m.%d.%y')\n\n\nDeaths <- data.table('date'=dts,\n                     'deaths'=colSums(D[,obs,with=F]))\nDeaths <- rbind(data.table('date'=seq(as.Date('2020-01-15'),min(Deaths$date-1),by='day'),\n                           'deaths'=0),Deaths)\nDeaths[,deaths:=c(diff(deaths),NA)]\n\nggplot(Deaths[date>as.Date('2020-03-01')],aes(date,deaths))+\n  geom_point()+\n  scale_y_continuous(trans='log',breaks=10^(0:4))\n\nfit <- glm(deaths~date,family=poisson,data=Deaths[date>as.Date('2020-03-04')])\nd_death <- function(x,fit.=fit) dnorm(x,mean = fit$coefficients[2],sd=sqrt(vcov(fit)[4]))\nr_death <- coef(fit)[2]\n\n\nlag=27\nDeaths[deaths==0,deaths:=NA]\nDeaths[,lagged_deaths:=shift(deaths,n=lag,type='lead')]\nsetkey(Deaths,date)\nsetkey(US,date)\n\nX <- US[Deaths]\n\nget_coef <- function(y,x){\n}\n\nsetkey(X,replicate,date)\nX[,cfr:=coef(glm(y~x+0,data=data.frame('y'=lagged_deaths,'x'=I))),by=replicate]\n\n\nX[,prob_curve:=d_death(GrowthRate)]\n\n\ntrajectory_summaries <- X[,list(cfr=unique(cfr),\n                                GrowthRate=unique(GrowthRate),\n                                prob_curve=unique(prob_curve),\n                                max_R=max(R)),by=replicate]\n\ncfr_distribution <- sample(trajectory_summaries$cfr,size=1e4,prob=trajectory_summaries$prob_curve,replace=T)\ntrajectory_summaries[,weighted.mean(cfr,prob_curve)]\n\nsummary(cfr_distribution)\nhist(log(cfr_distribution))\n\n\nset.seed(1)\nplotted_reps <- c(trajectory_summaries[,sample(replicate,size=8e2,prob = prob_curve,replace=F)]) %>% unique\nggplot(X[replicate %in% plotted_reps],aes(date,I,alpha=prob_curve,by=factor(replicate)))+\n  geom_line()+\n  geom_line(aes(date,lagged_deaths),col='red')+\n  geom_point(aes(date,lagged_deaths),col='red',cex=3)+\n  scale_y_continuous(trans='log',breaks=10^(0:10))+\n  scale_alpha_continuous(range=c(0.01,0.7))+\n  theme_bw()+\n  theme(legend.position = 'none')\n",
    "created" : 1586109292711.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1803749943",
    "id" : "786CC605",
    "lastKnownWriteTime" : 1586109828,
    "last_content_update" : 1586109828151,
    "path" : "~/Silverman/ili_surge/results/Excess_ILI_SEIR_analysis.R",
    "project_path" : "results/Excess_ILI_SEIR_analysis.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}